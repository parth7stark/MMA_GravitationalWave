import json
from omegaconf import OmegaConf, DictConfig
from proxystore.proxy import Proxy, extract
from typing import Union, Dict, OrderedDict, Tuple, Optional, Any
from mma_gw.agent import ClientAgent
from .utils import serialize_tensor_to_base64, deserialize_tensor_from_base64
from mma_gw.logger import ClientAgentFileLogger

from diaspora_event_sdk import KafkaProducer, KafkaConsumer


class OctopusClientCommunicator:
    """
    Octopus communicator for federated learning clients.
    Contains functions to produce/consume/handle different events
    """
    def __init__(
        self, 
        client_agent: ClientAgent,
        client_id: Union[str, int],
        logger: Optional[ClientAgentFileLogger] = None,
    ):
        """        
        :param client_id: A unique client ID.
        :param max_message_size: The maximum message size in bytes.
        """
        self.client_id = client_id
        self.client_agent = client_agent
        self.logger = logger if logger is not None else self._default_logger()
        

        self.topic = self.client_agent.client_agent_config.comm_configs.octopus_configs.topic


        # Kafka producer for control messages and sending Embeddings
        self.producer = KafkaProducer()


        client_group_id = self.client_agent.client_agent_config.comm_configs.octopus_configs.group_id
        self.consumer = KafkaConsumer(
            self.topic,
            enable_auto_commit=True,
            auto_offset_reset="earliest",  # This ensures it reads all past messages
            group_id=client_group_id
        )

    def on_server_started(self, data):
        """
        Called once the client sees the server is started and the config is published.
        We can parse the config or update local settings, then send 'ClientReady' event.
        """

        print(f"[Detector {self.client_agent.get_id()}] Received ServerStarted event.", flush=True)
        self.logger.info(f"[Detector {self.client_agent.get_id()}] Received ServerStarted event.")
        
        client_config = data["detector_config"]  # This is the dict from OmegaConf
        self.client_agent.load_config(client_config)

        # Now publish "DetectorReady"
        ready_msg = {
            "EventType": "DetectorReady",
            "Detector_id": self.client_id
        }
        self.producer.send(self.topic, ready_msg)
        self.producer.flush()
        print(f"[Detector {self.client_id}] Published DetectorReady event.")
        self.logger.info(f"[Detector {self.client_id}] Published DetectorReady event.")


    def send_embeddings_inference_Octopus(self, local_embeddings, **kwargs):
        """
        Send local embeddings to the server for inference via Octopus
        :param local_embeddings: The local embeddings generated by the client model.
        :param kwargs: Additional metadata to be sent to the server.
        :return: None for async and if sync communication return Metadata containing the server's acknowledgment status.
        """
        
        if '_client_id' in kwargs:
            client_id = str(kwargs["_client_id"])
            del kwargs["_client_id"]
        else:
            client_id = str(self.client_id)
        
        if self.client_agent.use_proxystore:
            local_embeddings = self.client_agent.proxystore.proxy(local_embeddings)

        # Serialize to base64
        embedding_b64 = serialize_tensor_to_base64(local_embeddings)

        # Build the JSON payload
        data = {
            "EventType": "SendEmbeddings",
            "detector_id": client_id,
            "batch_id": kwargs["batch_id"],
            "shift": kwargs["append_in"],
            "embedding": embedding_b64
        }
    
        self.producer.send(
            self.topic,
            value=data
        )

        self.producer.flush()

        print(f"[Detector {client_id}] Sent Embeddings: batch_id={kwargs['batch_id']}, shift={kwargs['append_in']}", flush=True)
        self.logger.info(f"[Detector {client_id}] Sent Embeddings: batch_id={kwargs['batch_id']}, shift={kwargs['append_in']}")

        return
    
    def invoke_post_process(self, GPSStartTime):
        """
        Publish PostProcess event to the server for invoking post process pipeline via Octopus
        :param GPS start time: Starting GPS time for the inference data
        :return: None for async and if sync communication return Metadata containing the server's acknowledgment status.
        """
        
        detector_id =  self.client_id
        done_msg = {
            "EventType": "PostProcess",
            "detector_id": detector_id,
            "status" : "DONE",
            "details": "All Embeddings sent for given time segment -> Invoke post process pipeline",
            "GPS_start_time": GPSStartTime
        }


        self.producer.send(
            self.topic,
            value=done_msg
        )
        
        print(f"[Detector {detector_id}] Publish PostProcess Event: GPS start time={GPSStartTime}", flush=True)
        self.logger.info(f"[Detector {detector_id}] Publish PostProcess Event: GPS start time={GPSStartTime}")

        self.producer.flush()
        
        return

    
    def _default_logger(self):
        """Create a default logger for the server if no logger provided."""
        logger = logging.getLogger(__name__)
        logger.setLevel(logging.INFO)
        fmt = logging.Formatter('[%(asctime)s %(levelname)-4s server]: %(message)s')
        s_handler = logging.StreamHandler()
        s_handler.setLevel(logging.INFO)
        s_handler.setFormatter(fmt)
        logger.addHandler(s_handler)
        return logger

